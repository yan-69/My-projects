{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KaggleChallange1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "13Q4bWadOKNSvgiqAmdAxki5o6Zh0yjkC",
      "authorship_tag": "ABX9TyM1sHW+MwSJR5NpVwdUYuS7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yan-69/My-projects/blob/master/KaggleChallange1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ypo9NZ23oTq"
      },
      "source": [
        "## **Importing the training data and changing into a pandas dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yscrbN-OsjNw"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "columns = [\"id\",\"keyword\",\"location\",\"text\",\"target\"];\r\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv',usecols=columns)\r\n",
        "\r\n",
        "print(df_train['text'][11:21])\r\n",
        "#print(df_train['target'][11:21])\r\n",
        "print(len(df_train[\"text\"]))\r\n",
        "print(len(df_train[\"target\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_UA28Xa35ZW"
      },
      "source": [
        "### ***Plotting the training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2F8-CCBx4IV"
      },
      "source": [
        "import seaborn as sns\r\n",
        "\r\n",
        "sns.countplot(\"target\",data=df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZGj7HmX4Sbn"
      },
      "source": [
        "### **Cleaning the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e54UzUYs1YeR"
      },
      "source": [
        "import string\r\n",
        "import re\r\n",
        "import random \r\n",
        "\r\n",
        "def text_cleaner(data):\r\n",
        "  ascii = set(string.printable)\r\n",
        "  cleaned_data = filter(lambda x : x in ascii, data)\r\n",
        "  cleaned_data = ''.join([char.lower() for char in data if char not in string.punctuation])\r\n",
        "  cleaned_data = re.sub('[0-9]+', '',cleaned_data)\r\n",
        "  return cleaned_data\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "df_train[\"cleaned_text\"] = df_train[\"text\"].apply(lambda x:text_cleaner(x))\r\n",
        "print(df_train[\"cleaned_text\"][:6])\r\n",
        "df_train = df_train.sample(frac=1).reset_index(drop=True)\r\n",
        "print(df_train[\"cleaned_text\"][:6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0-VOQ1P4WKL"
      },
      "source": [
        "### **Importing the test data and changing it into a pandas dataframe**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sYzeaIX3L39"
      },
      "source": [
        "test_columns = [\"id\",\"keyword\",\"location\",\"text\"]\r\n",
        "\r\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv',usecols=test_columns)\r\n",
        "#df_dev[\"text\"][:10]\r\n",
        "print(len(df_test[\"text\"]))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU3VLOEj5ML2"
      },
      "source": [
        "### **Cleaning the test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El1mbsCf_IEh"
      },
      "source": [
        "df_test[\"cleaned_data\"] = df_test[\"text\"].apply(lambda x: text_cleaner(x))\r\n",
        "\r\n",
        "df_test = df_test.sample(frac=1).reset_index(drop=True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtATepp__zg-"
      },
      "source": [
        "### **Preparing the data for training process**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JASKXodg_5hT"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras import regularizers\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "sentences=[]\r\n",
        "labels = []\r\n",
        "for i in range(len(df_train[\"text\"])):\r\n",
        "  sentences.append(df_train[\"text\"][i])\r\n",
        "  labels.append(df_train[\"target\"][i])\r\n",
        "\r\n",
        "#print(len(sentences))\r\n",
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(sentences)\r\n",
        "word_index = tokenizer.word_index\r\n",
        "vocab_size = len(word_index)\r\n",
        "\r\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\r\n",
        "padded_data = pad_sequences(sequences, maxlen = 32, padding = 'post', truncating = 'post')\r\n",
        "\r\n",
        "train_sentences = padded_data[:7500]\r\n",
        "train_labels = labels[:7500]\r\n",
        "dev_sentences = padded_data[7500:]\r\n",
        "dev_labels = labels[7500:]\r\n",
        "\r\n",
        "print(len(train_sentences))\r\n",
        "print(len(train_labels))\r\n",
        "print(len(dev_sentences))\r\n",
        "print(len(dev_labels))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51SmLSv_vH8T"
      },
      "source": [
        "embedding_dim = 100\r\n",
        "\r\n",
        "!wget --no-check-certificate \\\r\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\r\n",
        "    -O /tmp/glove.6B.100d.txt\r\n",
        "embeddings_index = {};\r\n",
        "with open('/tmp/glove.6B.100d.txt') as f:\r\n",
        "    for line in f:\r\n",
        "        values = line.split();\r\n",
        "        word = values[0];\r\n",
        "        coefs = np.asarray(values[1:], dtype='float32');\r\n",
        "        embeddings_index[word] = coefs;\r\n",
        "\r\n",
        "embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\r\n",
        "for word, i in word_index.items():\r\n",
        "    embedding_vector = embeddings_index.get(word);\r\n",
        "    if embedding_vector is not None:\r\n",
        "        embeddings_matrix[i] = embedding_vector;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVS2adIDvW9b"
      },
      "source": [
        "print(len(embeddings_matrix))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os0fxvHfrytC"
      },
      "source": [
        "### **Training process of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HY-0IIBl7MJ"
      },
      "source": [
        "model = tf.keras.Sequential()\r\n",
        "model.add(tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=32, weights=[embeddings_matrix], trainable=False))\r\n",
        "model.add(tf.keras.layers.Dropout(0.3))\r\n",
        "model.add(tf.keras.layers.Conv1D(16, 6, activation='relu'))\r\n",
        "model.add(tf.keras.layers.Conv1D(32, 6, activation='relu'))\r\n",
        "model.add(tf.keras.layers.Conv1D(64, 6, activation='relu'))\r\n",
        "forward_layer = tf.keras.layers.LSTM(128, return_sequences=False)\r\n",
        "backward_layer = tf.keras.layers.LSTM(128, activation='relu', return_sequences=False,\r\n",
        "                       go_backwards=True)\r\n",
        "model.add(tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer, input_shape=(5,10)))\r\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\r\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0001), metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHumzvlMtUnS"
      },
      "source": [
        "train_sentences = np.array(train_sentences)\r\n",
        "train_labels = np.array(train_labels)\r\n",
        "dev_sentences = np.array(dev_sentences)\r\n",
        "dev_labels = np.array(dev_labels)\r\n",
        "#print(train_labels)\r\n",
        "history = model.fit(train_sentences,train_labels, epochs = 20, validation_data = (dev_sentences,dev_labels), verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szdy6pAfwr7g"
      },
      "source": [
        "predicted_labels = np.round_(model.predict(dev_sentences))\r\n",
        "print(len(predicted_labels))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbZ8EMUfx9z4"
      },
      "source": [
        "\r\n",
        "h = []\r\n",
        "g = []\r\n",
        "j = 0\r\n",
        "for i in dev_labels:\r\n",
        "  h.append(i)\r\n",
        "for i in (predicted_labels.ravel().tolist()):\r\n",
        "  g.append(i)\r\n",
        "for x in range(len(dev_labels)):\r\n",
        "  if predicted_labels[x] == dev_labels[x]:\r\n",
        "    j+=1\r\n",
        "print(F\"You have {j} correct predictions out of {len(predicted_labels)}\")\r\n",
        "print(F\"Your model has {round(100*91/113)}% accuracy on unseen data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBRqlBnF1qa4"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "#plt.plot(predicted_labels, r')\r\n",
        "plt.plot(dev_labels,'v')\r\n",
        "#plt.plot(predicted_labels, 'v')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PwSAN1ozPjO"
      },
      "source": [
        "plt.plot(predicted_labels,'v')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyEcIuhS2zXA"
      },
      "source": [
        "train_acc = history.history['accuracy']\r\n",
        "dev_acc = history.history['val_accuracy']\r\n",
        "train_loss = history.history['loss']\r\n",
        "dev_loss = history.history['val_loss']\r\n",
        "epochs = range(len(train_acc))\r\n",
        "plt.plot(epochs, train_acc, 'r')\r\n",
        "plt.plot(epochs, dev_acc, 'g')\r\n",
        "plt.title(\"Training accuracy vs dev accuracy\")\r\n",
        "plt.xlabel(\"Eapochs\")\r\n",
        "plt.ylabel(\"Accuracy\")\r\n",
        "plt.legend([\"Train_acc\",\"Dev_acc\"])\r\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmnOsJE3QEr3"
      },
      "source": [
        "plt.plot(epochs, train_loss, 'b')\r\n",
        "plt.plot(epochs, dev_loss, 'g')\r\n",
        "plt.title(\"Training vs Dev loss\")\r\n",
        "plt.xlabel(\"Training loss\")\r\n",
        "plt.ylabel(\"Dev loss\")\r\n",
        "plt.legend([\"Training_loss\",\"Dev_loss\"])\r\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLbrP8NsWoin"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}