{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cat_vs_dog classifier.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNvFhe7gqEPALJgRp3Zgb81",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yan-69/My-projects/blob/master/cat_vs_dog_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6UrUPVbrK9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "  -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUR0Hu3Hrcx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "ziP = zipfile.ZipFile(local_zip,'r')\n",
        "\n",
        "ziP.extractall('/tmp')\n",
        "ziP.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89zn9S1ysFsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered/'\n",
        "\n",
        "train_dir = os.path.join(base_dir , 'train')\n",
        "validation_dir = os.path.join(base_dir , 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir , 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir , 'dogs')\n",
        "\n",
        "valid_cats_dir = os.path.join(validation_dir , 'cats')\n",
        "valid_dogs_dir = os.path.join(validation_dir , 'dogs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4VsL-UVuCLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"total training cats images :\" , len(os.listdir(train_cats_dir)))\n",
        "print(\"total training dogs images :\" , len(os.listdir(train_dogs_dir)))\n",
        "print(\"total validation cats images :\" , len(os.listdir(valid_cats_dir)))\n",
        "print(\"total validaiton dogs images :\" ,len(os.listdir(valid_dogs_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSF8QOY3y9Ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image as pimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rows = 4\n",
        "columns = 4\n",
        "\n",
        "index  = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlE6Gf0hz2UZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cat_fnames = os.listdir( train_cats_dir )\n",
        "train_dog_fnames = os.listdir( train_dogs_dir )\n",
        "\n",
        "figure = plt.gcf()\n",
        "\n",
        "figure.set_size_inches(4*rows , 4*columns)\n",
        "\n",
        "index += 8\n",
        "\n",
        "next_cat = [ os.path.join(train_cats_dir , fname)\n",
        "                                  for fname in train_cat_fnames[index-8:index] \n",
        "            ]\n",
        "next_dog = [os.path.join(train_dogs_dir , fname)\n",
        "                                  for fname in train_dog_fnames[index-8:index]\n",
        "            ]\n",
        "\n",
        "for i,img_path in enumerate(next_cat+next_dog):\n",
        "  s = plt.subplot(rows,columns, i+1)\n",
        "  s.axis('Off')\n",
        "\n",
        "  img = pimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "  plt.plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WmBgD2P7e5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Conv2D(16,(3,3) , activation = 'relu' , input_shape=(150,150,3)),\n",
        "                             tf.keras.layers.MaxPooling2D(2,2),\n",
        "                             tf.keras.layers.Conv2D(32 , (3,3) , activation = 'relu'),\n",
        "                             tf.keras.layers.MaxPooling2D(2,2),\n",
        "                             tf.keras.layers.Conv2D(64 , (3,3) , activation = 'relu'),\n",
        "                             tf.keras.layers.MaxPooling2D(2,2),\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dense(512 , activation = 'relu'),\n",
        "                             tf.keras.layers.Dense(1 , activation = 'sigmoid')\n",
        "\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMoOMJgtB6V6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile( optimizer = RMSprop(lr = 0.001),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF48FcWfCd5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen =  ImageDataGenerator(rescale = 1/255)\n",
        "validation_datagen =  ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir ,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    target_size = (150 , 150))\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
        "                                                              batch_size = 20,\n",
        "                                                              class_mode = 'binary',\n",
        "                                                              target_size = (150 , 150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7qZFQP7EET_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = validation_generator,\n",
        "    steps_per_epoch = 100,\n",
        "    epochs = 15,\n",
        "    validation_steps = 50,\n",
        "    verbose = 2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSMe-eQGCgKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path='/content/' + fn\n",
        "  img=image.load_img(path, target_size=(150, 150))\n",
        "  \n",
        "  x=image.img_to_array(img)\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(classes[0])\n",
        "  \n",
        "  if classes[0]>0:\n",
        "    print(fn + \" is a dog\")\n",
        "    \n",
        "  else:\n",
        "    print(fn + \" is a cat\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPkGBoHAK-y_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from   tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model after\n",
        "# the first.\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "\n",
        "#visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "\n",
        "# Let's prepare a random input image of a cat or dog from the training set.\n",
        "cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]\n",
        "dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]\n",
        "\n",
        "img_path = random.choice(cat_img_files + dog_img_files)\n",
        "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
        "\n",
        "x   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)\n",
        "x   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255.0\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Now let's display our representations\n",
        "# -----------------------------------------------------------------------\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  \n",
        "  if len(feature_map.shape) == 4:\n",
        "    \n",
        "    #-------------------------------------------\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    #-------------------------------------------\n",
        "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
        "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
        "    \n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    \n",
        "    #-------------------------------------------------\n",
        "    # Postprocess the feature to be visually palatable\n",
        "    #-------------------------------------------------\n",
        "    for i in range(n_features):\n",
        "      x  = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std ()\n",
        "      x *=  64\n",
        "      x += 128\n",
        "      x  = np.clip(x, 0, 255).astype('uint8')\n",
        "      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n",
        "\n",
        "    #-----------------\n",
        "    # Display the grid\n",
        "    #-----------------\n",
        "\n",
        "    scale = 20. / n_features\n",
        "    plt.figure( figsize=(scale * n_features, scale) )\n",
        "    plt.title ( layer_name )\n",
        "    plt.grid  ( False )\n",
        "    plt.imshow( display_grid, aspect='auto', cmap='viridis' ) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}